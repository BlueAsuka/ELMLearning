{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "torch.cuda.manual_seed(1) if USE_CUDA else torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if USE_CUDA else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-05 13:30:12.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mLoaded the configuration file.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import loguru\n",
    "\n",
    "with open('../configs/cnn_configs.json', 'r') as f:\n",
    "    configs = json.load(f)\n",
    "    loguru.logger.info('Loaded the configuration file.')\n",
    "\n",
    "BATCH_SIZE = configs['BATCH_SIZE']\n",
    "LR = configs['LR']\n",
    "MOMENTUM = configs['MOMENTUM']\n",
    "EPOCHS = configs['EPOCHS']\n",
    "LOG_INTERVAL = configs['LOG_INTERVAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        loguru.logger.debug(f'params num: {sum(p.numel() for p in self.parameters() if p.requires_grad)}')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-04 19:01:16.196\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1mparams num: 21840\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "if USE_CUDA:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if USE_CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if USE_CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target).item()\n",
    "            pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data).cpu().sum()\n",
    "    \n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.354873\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.042626\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.233654\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.993994\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.799430\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.756497\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.486018\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.549505\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.604204\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.500301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-04 18:00:07.568\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mTime for the epoch: 17.4860s.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2244, Accuracy: 9348/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.442255\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.464616\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.376070\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.606645\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.455777\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.237125\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.460890\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.289720\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.286341\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.551159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-04 18:00:21.672\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mTime for the epoch: 10.6831s.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1278, Accuracy: 9623/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.392027\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.165389\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.424578\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.509329\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.418495\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.252133\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.298127\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.395802\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.142130\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.293039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-04 18:00:35.739\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mTime for the epoch: 10.7143s.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0912, Accuracy: 9704/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.570343\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.210215\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.239513\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.284521\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.277017\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.194479\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.268238\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.142656\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.309105\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.198461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-04 18:00:49.847\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mTime for the epoch: 10.7178s.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0785, Accuracy: 9761/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.296541\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.216423\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.276908\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.323216\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.280068\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.148496\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.200388\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.505394\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.583515\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.146169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-04 18:01:03.762\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mTime for the epoch: 10.6005s.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0720, Accuracy: 9777/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.301349\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.181185\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.219239\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.191215\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.395132\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.111943\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.228657\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.209885\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.176035\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.145297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-04 18:01:17.863\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mTime for the epoch: 10.7315s.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0628, Accuracy: 9796/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.269095\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.184704\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.164736\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.183019\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.255718\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.171387\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.236074\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.189220\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.214841\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.184442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-04 18:01:31.929\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mTime for the epoch: 10.6869s.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0575, Accuracy: 9812/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.155774\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.391023\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.358278\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.221706\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.289638\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.215661\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.168890\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.177473\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.213027\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.335257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-04 18:01:45.861\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mTime for the epoch: 10.5611s.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0574, Accuracy: 9814/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.148728\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.121965\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.217122\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.172365\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.114969\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.055023\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.100465\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.119181\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.137933\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.299993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-04 18:01:59.868\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mTime for the epoch: 10.6024s.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0491, Accuracy: 9840/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.208018\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.148983\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.145555\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.278376\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.355840\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.264135\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.117086\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.171919\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.186838\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.350923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-04 18:02:13.953\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mTime for the epoch: 10.7101s.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0482, Accuracy: 9846/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    init = time.time()\n",
    "    train(epoch)\n",
    "    ending = time.time()\n",
    "    loguru.logger.debug(f'Time for the epoch: {ending - init:.4f}s.')\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../model/cnn/mnist_cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[-2.2801e-01, -2.0178e-01,  1.1392e-01,  1.4996e-01,  6.7549e-02],\n",
       "                        [-2.4287e-01, -8.0902e-03,  4.7206e-02, -8.0363e-02, -7.8436e-02],\n",
       "                        [-2.5816e-01, -2.2800e-01, -1.5778e-01, -6.3274e-02, -1.7308e-01],\n",
       "                        [-1.3900e-01,  1.3632e-02, -5.6343e-02, -1.5601e-01, -2.3128e-01],\n",
       "                        [-1.1529e-01, -1.5112e-01, -1.7182e-01, -1.0877e-01,  5.7885e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.6658e-01,  4.1212e-01,  4.6037e-01,  2.5170e-01,  8.1825e-02],\n",
       "                        [ 1.3873e-01,  2.6663e-01,  5.7617e-02, -9.3925e-02, -9.6656e-02],\n",
       "                        [ 2.5818e-01, -1.6053e-01, -3.8164e-01, -1.0151e-01, -2.5368e-01],\n",
       "                        [-1.1415e-01, -3.3096e-01, -1.5438e-01, -2.7884e-01,  1.0435e-01],\n",
       "                        [-1.9238e-01, -3.3290e-01, -5.2033e-02,  1.6483e-01,  2.0401e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0834e-02, -1.4370e-01, -3.6695e-01, -3.2373e-01, -1.8022e-01],\n",
       "                        [-1.1292e-02,  1.8376e-01,  2.8625e-01,  2.7493e-01,  5.5191e-02],\n",
       "                        [ 1.0511e-01,  2.3921e-01,  1.4229e-01,  3.9019e-01,  8.0329e-02],\n",
       "                        [ 3.8339e-02,  1.3067e-01, -2.3294e-01,  8.1259e-02, -6.5648e-02],\n",
       "                        [-2.7528e-01, -3.4760e-01, -2.2254e-01,  6.2742e-03, -1.2735e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.9815e-02,  2.7322e-01,  1.6659e-01, -2.5101e-01, -5.7366e-04],\n",
       "                        [ 2.3266e-02,  1.2218e-01, -4.4910e-02, -3.1901e-01,  2.4477e-01],\n",
       "                        [ 2.5414e-01,  2.5838e-01, -2.4670e-01,  8.3774e-02,  3.2285e-01],\n",
       "                        [ 2.1079e-01, -3.3329e-02, -1.6835e-01, -6.5649e-02,  9.7955e-02],\n",
       "                        [ 2.6815e-02,  3.4944e-02,  4.6676e-02,  3.2292e-02,  5.1746e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.2776e-02, -1.3475e-01, -4.8227e-01, -3.2244e-01, -3.2480e-01],\n",
       "                        [ 5.7399e-02, -4.2962e-02, -5.1290e-01, -3.5905e-01, -5.0127e-01],\n",
       "                        [ 2.9096e-01,  4.2721e-01,  3.1456e-01, -2.1003e-02, -3.4788e-02],\n",
       "                        [ 4.3492e-02,  4.9689e-01,  6.2870e-01,  2.9607e-01,  1.0243e-01],\n",
       "                        [-3.0192e-01, -5.0400e-02,  1.2826e-01,  4.1935e-01,  3.9096e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7305e-02,  4.6600e-02,  3.5223e-01,  1.6531e-01, -1.1147e-01],\n",
       "                        [ 1.9658e-01,  3.3402e-01,  3.3478e-01, -1.0046e-01, -6.1750e-02],\n",
       "                        [ 1.8126e-01,  1.4521e-01,  2.2138e-01, -1.8166e-02, -4.1508e-01],\n",
       "                        [ 2.5956e-01,  2.6595e-01,  3.0578e-01, -3.0116e-02, -2.3983e-01],\n",
       "                        [-1.7785e-01, -5.2801e-03,  2.4333e-01,  2.1177e-01, -8.1880e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3734e-01, -3.4963e-01, -4.2560e-01,  1.6414e-02,  2.6938e-01],\n",
       "                        [-4.6172e-01, -1.7577e-01, -4.6512e-02,  1.7132e-01,  1.6714e-01],\n",
       "                        [-2.9304e-01, -2.1728e-01,  6.4595e-03,  4.4412e-01,  2.8694e-01],\n",
       "                        [-3.7351e-01,  4.9123e-02,  3.8347e-01,  1.9896e-01,  7.5152e-02],\n",
       "                        [-6.3557e-02,  1.4917e-01,  3.0494e-01,  1.8187e-01,  1.5328e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1940e-01,  1.7387e-01,  2.8444e-01,  3.7104e-01, -1.9617e-02],\n",
       "                        [-1.9760e-01, -1.2292e-01, -1.9815e-02,  3.9858e-01,  1.9666e-01],\n",
       "                        [-2.3194e-01, -1.0386e-01, -1.3134e-01,  2.8618e-01,  1.5665e-01],\n",
       "                        [-3.4238e-01, -2.6698e-01,  1.6448e-03,  3.3726e-01,  2.1583e-01],\n",
       "                        [-4.0894e-01, -1.7477e-01, -1.5354e-01,  2.0042e-02,  2.5701e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.1368e-01,  1.3351e-01, -5.5148e-02, -2.1653e-01,  1.1043e-01],\n",
       "                        [ 3.4387e-01, -1.8721e-01, -2.8655e-01, -1.4685e-01, -1.1945e-01],\n",
       "                        [ 4.7162e-02, -2.0014e-01,  5.5234e-02, -1.3116e-01, -2.5796e-01],\n",
       "                        [ 6.8490e-02, -7.5754e-02, -1.2830e-01, -1.3478e-01,  4.2439e-02],\n",
       "                        [-1.5202e-01, -2.0847e-01, -1.5061e-01, -1.1917e-01,  6.1659e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.2473e-02,  2.4875e-02, -1.3732e-01, -7.6556e-02,  1.5650e-01],\n",
       "                        [-1.6087e-01,  9.2971e-03, -9.4179e-02,  1.5672e-01, -8.2630e-02],\n",
       "                        [ 3.6898e-02,  1.0694e-01, -1.3059e-01, -1.1749e-01,  1.0647e-01],\n",
       "                        [-1.9401e-01, -1.2951e-01, -2.4207e-02, -1.3496e-02,  1.3727e-01],\n",
       "                        [ 1.3450e-02, -1.2367e-01, -2.6379e-02, -2.0370e-01,  1.9799e-01]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([ 0.2144,  0.0651,  0.0599,  0.2499,  0.2455,  0.0322, -0.1857, -0.2502,\n",
       "                      -0.0469, -0.0766])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[ 2.7652e-02,  4.3965e-02,  2.8372e-02,  1.0499e-02, -2.9192e-02],\n",
       "                        [-4.8176e-02,  9.0873e-03, -9.9220e-02, -1.8968e-02,  2.9593e-02],\n",
       "                        [ 7.4679e-03, -4.0134e-02, -7.4703e-02, -9.4519e-03,  2.0986e-02],\n",
       "                        [ 5.4189e-02, -6.7290e-03, -1.0040e-02, -1.9341e-02, -1.0111e-01],\n",
       "                        [ 7.7664e-02, -1.8982e-02,  3.6326e-02, -4.3612e-03,  7.2148e-02]],\n",
       "              \n",
       "                       [[ 6.1494e-02, -9.1019e-02, -6.8833e-02, -1.2962e-02, -2.3788e-02],\n",
       "                        [-4.2058e-02, -1.0202e-02,  8.4083e-02,  6.5606e-02, -2.9875e-02],\n",
       "                        [-6.5273e-03, -1.0069e-01, -3.7975e-02,  4.5952e-03,  2.0426e-03],\n",
       "                        [-8.3999e-02, -1.3824e-01, -8.2561e-02, -5.3353e-03,  1.1243e-01],\n",
       "                        [-8.4053e-02,  1.8479e-02, -4.0656e-02,  5.6797e-02,  6.2305e-02]],\n",
       "              \n",
       "                       [[ 1.9163e-02,  1.6891e-02,  9.5120e-04,  1.5550e-02,  6.6750e-02],\n",
       "                        [ 3.3819e-02, -6.8838e-02, -2.2845e-02,  6.3090e-02,  8.4704e-02],\n",
       "                        [-3.2036e-02,  5.5401e-03, -3.1945e-02,  1.1447e-01,  1.7468e-01],\n",
       "                        [-3.2770e-02,  2.0414e-02,  5.7691e-02,  6.4932e-02,  1.1735e-01],\n",
       "                        [-2.3076e-02,  4.9552e-02,  1.0197e-01,  9.4572e-02,  3.9779e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.3501e-02, -1.0090e-02,  3.0091e-02, -1.3410e-01, -1.0243e-01],\n",
       "                        [-1.9843e-02, -9.5685e-03, -2.9820e-02, -1.1743e-01,  2.9798e-02],\n",
       "                        [ 6.2384e-02,  4.9535e-02,  3.4807e-02, -6.8037e-02, -8.8702e-02],\n",
       "                        [ 4.0366e-02,  1.6404e-01,  4.4725e-02, -8.7868e-02, -6.8319e-02],\n",
       "                        [ 8.8024e-02,  3.6409e-02,  6.6687e-02, -7.8379e-02, -1.1494e-01]],\n",
       "              \n",
       "                       [[-3.8917e-04, -1.4961e-03, -1.8311e-02,  8.1952e-02, -5.6914e-02],\n",
       "                        [ 4.7083e-02,  3.2290e-02,  1.2006e-01,  9.3704e-02, -1.0582e-01],\n",
       "                        [ 5.9003e-02, -4.6003e-02, -5.6914e-02, -2.4202e-02, -1.0767e-01],\n",
       "                        [ 7.7070e-04,  4.4397e-02, -3.5349e-02, -5.1780e-02,  5.9237e-02],\n",
       "                        [ 6.5588e-02,  5.2258e-02,  1.0392e-02, -4.8061e-02,  8.6648e-03]],\n",
       "              \n",
       "                       [[ 2.3499e-02,  3.7622e-02,  3.7828e-02, -4.1507e-02, -1.3443e-02],\n",
       "                        [ 2.7158e-02,  6.4251e-02, -6.5419e-03,  1.5501e-02, -2.8413e-03],\n",
       "                        [ 5.0024e-03,  4.0245e-02,  1.3870e-03, -4.6462e-02, -2.5945e-02],\n",
       "                        [-3.0944e-02, -1.5977e-02, -8.2003e-03, -6.7039e-02,  2.1768e-02],\n",
       "                        [-5.4530e-04,  3.4802e-02, -6.5060e-02, -2.3149e-02, -5.7829e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.1253e-03,  5.2821e-03, -2.0000e-03, -1.2449e-02,  2.0802e-02],\n",
       "                        [ 3.0733e-02,  3.1628e-02,  1.7440e-02,  8.1197e-02,  6.8194e-02],\n",
       "                        [-8.1543e-03, -1.1840e-02, -5.2447e-02,  1.1635e-02,  9.6328e-03],\n",
       "                        [ 2.5720e-02,  5.0486e-02,  1.9746e-02, -2.8300e-02, -5.6662e-02],\n",
       "                        [-3.2271e-02,  3.0060e-02, -3.4685e-02, -5.3449e-02, -2.7261e-02]],\n",
       "              \n",
       "                       [[-7.6785e-02, -4.4618e-02, -3.2391e-02, -5.8963e-02, -4.3270e-02],\n",
       "                        [-3.0333e-02, -5.5847e-02, -8.7442e-02, -3.7235e-02, -8.6907e-02],\n",
       "                        [ 1.6291e-01,  5.6237e-02, -9.9090e-02, -9.5827e-02, -9.2178e-02],\n",
       "                        [ 8.6095e-02,  1.2960e-02, -4.1412e-02, -4.7246e-02, -3.6228e-03],\n",
       "                        [ 8.9881e-02,  1.0222e-01,  5.1057e-02,  4.8097e-02,  6.0095e-02]],\n",
       "              \n",
       "                       [[ 4.9406e-03, -4.1836e-02, -1.6211e-03, -6.7624e-02, -6.2576e-02],\n",
       "                        [ 7.2106e-03,  6.5293e-02,  4.8248e-02, -5.6531e-03, -1.6165e-02],\n",
       "                        [ 1.3843e-02,  9.7754e-02,  2.4233e-02, -4.7122e-02,  1.1341e-02],\n",
       "                        [ 3.5209e-02,  6.5980e-02,  1.7455e-02,  3.7748e-02, -2.4133e-02],\n",
       "                        [ 9.0632e-03, -3.5786e-02, -4.3023e-03,  2.4559e-02, -6.8255e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.9840e-02, -7.2199e-03, -3.2304e-02,  1.2966e-02,  8.1655e-02],\n",
       "                        [-1.9373e-01, -9.1678e-02, -9.7577e-02,  6.0987e-02, -2.1903e-02],\n",
       "                        [-1.3496e-01,  2.1444e-03, -3.4891e-02, -2.6105e-02,  6.2474e-02],\n",
       "                        [-2.2458e-02,  5.6895e-02,  5.5629e-02,  8.5765e-02, -6.8571e-02],\n",
       "                        [-7.7870e-02, -1.6168e-02, -6.7139e-02, -1.0526e-03, -1.1409e-01]],\n",
       "              \n",
       "                       [[-5.4682e-02,  3.2177e-02, -5.6918e-02, -3.8635e-02,  6.1287e-02],\n",
       "                        [-6.7608e-02, -7.4396e-02, -5.7949e-03, -1.4935e-02, -1.7896e-02],\n",
       "                        [-2.1632e-02, -5.5341e-02, -6.9534e-02, -2.6934e-02, -5.5543e-02],\n",
       "                        [ 2.9855e-02, -2.8302e-02,  5.3183e-02,  5.7179e-03, -1.5962e-02],\n",
       "                        [-3.0497e-02, -2.4488e-02,  2.3629e-02,  3.4287e-02,  8.7148e-02]],\n",
       "              \n",
       "                       [[-5.8696e-02,  8.9092e-03,  3.7574e-02,  1.5355e-02, -9.5731e-04],\n",
       "                        [ 4.8044e-03, -5.8987e-02,  7.3294e-03,  6.3324e-02, -2.1220e-02],\n",
       "                        [ 2.4661e-02,  3.0350e-02, -5.6097e-03, -2.0159e-02,  1.4513e-02],\n",
       "                        [-3.3428e-02, -3.5548e-02, -5.0868e-02,  2.2976e-02, -2.4765e-02],\n",
       "                        [-4.0566e-02, -4.9591e-02, -2.7839e-02,  5.0218e-02,  1.7713e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.0231e-02, -2.3017e-02,  2.2270e-02, -7.3121e-02, -3.0780e-03],\n",
       "                        [-6.7798e-02, -4.1530e-02, -2.8779e-03,  1.2241e-02, -5.3641e-02],\n",
       "                        [ 2.0934e-02,  6.2706e-02, -4.2110e-02,  7.4543e-02, -8.6162e-02],\n",
       "                        [ 4.5156e-02, -2.8268e-02, -2.6933e-02,  1.3671e-02, -8.1250e-02],\n",
       "                        [ 2.0817e-02, -1.5231e-02, -7.1280e-02,  2.8417e-02, -9.4111e-02]],\n",
       "              \n",
       "                       [[ 6.2989e-02, -2.4904e-02, -3.9811e-02, -6.7569e-02, -6.8400e-02],\n",
       "                        [-9.5381e-03, -9.5657e-02,  1.8239e-03,  2.0024e-02, -4.0226e-03],\n",
       "                        [-3.4021e-02,  3.2746e-02,  4.7350e-02,  9.8847e-04, -8.8994e-02],\n",
       "                        [ 4.1246e-02,  3.2747e-02,  1.1914e-02, -5.6727e-03, -4.2082e-02],\n",
       "                        [ 1.1308e-01,  2.3717e-02, -2.1673e-02,  6.5715e-02, -2.7333e-02]],\n",
       "              \n",
       "                       [[-4.8101e-02, -2.8521e-02, -4.1934e-02,  3.9360e-03, -1.3721e-04],\n",
       "                        [ 1.8909e-02, -3.2012e-03, -2.3938e-02,  8.5432e-02,  4.6130e-02],\n",
       "                        [-4.9041e-02, -2.3677e-02,  2.1618e-03, -2.9461e-02, -1.6130e-05],\n",
       "                        [-4.4201e-02, -5.6755e-02, -5.8162e-02,  2.3726e-04, -4.1942e-02],\n",
       "                        [-4.9877e-04,  4.0571e-03,  7.2314e-03,  1.9817e-02, -9.3673e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.4332e-02, -4.7049e-02,  3.8003e-02, -1.7715e-02,  6.0280e-02],\n",
       "                        [ 8.3847e-03,  2.8528e-02,  9.7544e-03,  6.1924e-02,  6.7490e-02],\n",
       "                        [ 5.7827e-02, -7.6990e-02, -3.5559e-02, -2.3983e-02,  7.7810e-02],\n",
       "                        [-2.4709e-02, -9.0120e-03, -5.6068e-02, -3.9635e-02, -3.3779e-02],\n",
       "                        [-6.5723e-02, -8.9499e-03,  7.2755e-03, -4.5545e-02, -3.8058e-03]],\n",
       "              \n",
       "                       [[-6.8982e-02,  4.2842e-02,  1.0310e-02, -1.8776e-02, -7.1296e-02],\n",
       "                        [-1.0870e-02, -3.1454e-02, -3.5959e-02, -6.5316e-02, -2.4092e-02],\n",
       "                        [-3.6800e-02, -1.2095e-02,  3.1020e-02,  5.4529e-02,  1.6366e-02],\n",
       "                        [-7.6670e-03,  1.7323e-02,  1.0553e-02, -2.9557e-02, -3.9480e-02],\n",
       "                        [-1.1515e-02,  4.4095e-02,  6.6145e-02, -3.5762e-02,  8.0241e-02]],\n",
       "              \n",
       "                       [[-5.6074e-03, -1.7830e-02,  1.6580e-02, -2.2874e-02,  5.4612e-02],\n",
       "                        [-4.4429e-02, -6.2892e-02,  2.8518e-02, -5.8898e-02,  4.5964e-03],\n",
       "                        [-2.9839e-04, -2.6476e-02, -3.6335e-03, -3.6216e-02, -3.0095e-02],\n",
       "                        [-1.8030e-02, -2.6188e-02, -2.3483e-02, -1.7785e-02,  6.1850e-02],\n",
       "                        [ 3.0744e-02,  4.2449e-02, -2.1336e-03,  3.2636e-02, -1.4207e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.7979e-02, -7.9649e-02, -2.6647e-02, -4.4691e-02, -1.6899e-02],\n",
       "                        [ 2.1671e-03,  9.9578e-03, -7.7981e-02,  1.5881e-03, -8.5854e-02],\n",
       "                        [ 3.2717e-02, -3.7181e-02, -7.9652e-02,  3.8032e-02,  4.1037e-02],\n",
       "                        [-3.9027e-02, -1.0020e-02,  3.0758e-02,  6.8811e-02,  3.5445e-02],\n",
       "                        [ 6.5174e-02, -1.9171e-02, -1.1332e-02,  4.3098e-03, -5.8448e-02]],\n",
       "              \n",
       "                       [[ 7.7142e-03, -1.8098e-02, -8.8627e-02, -7.3654e-02, -1.2794e-02],\n",
       "                        [ 5.1811e-02, -9.5742e-02, -6.2200e-02, -1.6161e-02, -1.0855e-01],\n",
       "                        [-1.4146e-02, -2.5904e-02, -1.9292e-02, -2.3636e-02, -4.9462e-02],\n",
       "                        [ 4.7996e-02,  2.8799e-02,  1.2371e-01,  1.0596e-01, -2.9808e-02],\n",
       "                        [ 6.4015e-02,  1.0219e-01,  3.2217e-02,  1.3675e-02, -1.3550e-01]],\n",
       "              \n",
       "                       [[ 4.2556e-02,  4.8087e-02, -9.4518e-02, -2.7935e-02, -4.2583e-02],\n",
       "                        [ 5.9198e-02, -3.2738e-02, -5.4531e-03,  7.1279e-02,  6.3590e-02],\n",
       "                        [ 9.2339e-02,  9.5402e-03, -3.6440e-02, -2.6024e-03,  6.8731e-02],\n",
       "                        [ 4.1317e-02,  1.6640e-02,  3.1692e-02, -5.8572e-02, -4.9416e-02],\n",
       "                        [ 1.0117e-01,  4.2349e-02, -6.3408e-02, -1.1077e-02,  1.1711e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5917e-01,  6.4301e-02,  3.0945e-02, -3.5477e-02, -4.5310e-02],\n",
       "                        [-1.6582e-02,  2.6658e-02,  1.5386e-01,  2.7849e-02,  1.1088e-01],\n",
       "                        [ 2.6508e-02,  8.0607e-02,  7.2984e-02, -8.5001e-03,  1.7690e-01],\n",
       "                        [-1.8522e-02,  8.4847e-03, -3.5339e-02,  5.3664e-02,  1.4198e-01],\n",
       "                        [-2.8476e-02, -4.4043e-02,  3.2433e-02,  1.0062e-01,  1.0641e-01]],\n",
       "              \n",
       "                       [[-8.8694e-02,  1.5780e-03,  4.8015e-02,  8.2935e-03,  2.1078e-02],\n",
       "                        [-8.7066e-03, -1.2710e-01,  1.0113e-02, -3.5024e-02,  2.0566e-03],\n",
       "                        [-6.1633e-02, -7.8131e-02,  4.3191e-02,  5.3877e-02,  3.1103e-02],\n",
       "                        [ 2.7564e-02,  1.2865e-02,  4.3999e-02, -3.5885e-02, -1.8128e-02],\n",
       "                        [-3.7961e-02,  3.9990e-02,  2.7354e-02, -9.0795e-02, -7.6362e-02]],\n",
       "              \n",
       "                       [[-7.9853e-02,  5.7215e-02, -2.3250e-02,  2.5926e-02, -2.0427e-02],\n",
       "                        [ 2.7447e-03, -3.9133e-02, -3.6773e-02,  4.7970e-02, -4.8443e-02],\n",
       "                        [ 3.0651e-02, -3.2388e-02, -1.6415e-02,  3.9840e-02,  8.8765e-03],\n",
       "                        [-1.2138e-03,  4.7783e-02,  5.6088e-02, -9.7839e-03,  3.9509e-02],\n",
       "                        [ 3.3857e-02, -4.1968e-02,  6.8146e-02, -5.3995e-02, -5.6175e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7546e-02, -1.4219e-02, -9.2796e-02, -2.6786e-02, -6.8747e-02],\n",
       "                        [ 6.1631e-02, -7.9908e-02, -9.7423e-02, -3.1046e-02, -5.0373e-02],\n",
       "                        [-1.4690e-02,  4.5443e-02,  1.1672e-02,  1.2800e-02,  2.2179e-02],\n",
       "                        [ 1.2060e-01,  5.2714e-02, -2.7640e-02, -5.7628e-02, -3.8972e-02],\n",
       "                        [ 7.6146e-02,  1.4540e-02,  5.4184e-02,  2.7097e-02,  5.9108e-03]],\n",
       "              \n",
       "                       [[-1.2141e-01, -5.5730e-02, -2.3253e-02, -1.2567e-01, -6.7991e-03],\n",
       "                        [-4.1655e-02,  7.1059e-02,  8.0793e-02,  6.7895e-02, -4.9226e-02],\n",
       "                        [-5.8468e-03,  1.0239e-01,  6.5647e-02,  3.3312e-02, -8.8562e-02],\n",
       "                        [ 8.2494e-03,  1.1177e-01,  5.4241e-02,  2.8675e-02, -3.1720e-02],\n",
       "                        [ 4.7189e-02,  3.2362e-02, -6.5313e-02, -5.0479e-02, -7.3160e-02]],\n",
       "              \n",
       "                       [[-1.6330e-02, -3.5715e-02, -4.6056e-02,  5.5438e-02,  3.6032e-03],\n",
       "                        [-7.0992e-04,  7.5438e-02,  5.3201e-02,  5.4745e-02,  8.9503e-03],\n",
       "                        [ 8.1695e-02,  5.8268e-02,  1.1655e-01,  2.2217e-02, -2.8927e-02],\n",
       "                        [-3.4036e-02,  6.3607e-03,  2.6872e-02,  2.8948e-02,  2.9315e-02],\n",
       "                        [-7.2359e-02, -3.0127e-02,  1.0709e-02,  1.8908e-02,  2.1212e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.1602e-02, -7.4695e-02, -8.1770e-02, -8.0309e-02, -1.2390e-01],\n",
       "                        [ 7.2886e-02,  7.3275e-02, -5.0288e-03,  6.2332e-02, -1.0088e-02],\n",
       "                        [ 4.7533e-02,  4.0093e-02,  1.0894e-01,  1.2549e-01, -4.6611e-03],\n",
       "                        [ 2.9177e-02, -5.5274e-02, -4.6845e-02,  4.7199e-02, -2.8451e-02],\n",
       "                        [ 3.7780e-02, -1.0123e-01, -1.3647e-01, -2.6013e-02,  3.8824e-03]],\n",
       "              \n",
       "                       [[-7.6140e-03, -3.6572e-02, -6.6504e-02,  7.0084e-02,  7.3130e-02],\n",
       "                        [ 1.9336e-02, -2.5026e-02, -6.4047e-02, -3.2214e-03,  2.7139e-02],\n",
       "                        [ 9.0298e-03, -3.5595e-02,  3.5164e-02,  4.5769e-02,  5.6944e-02],\n",
       "                        [-3.8890e-02,  1.0190e-02, -5.5703e-02,  8.3242e-02,  4.8930e-02],\n",
       "                        [-1.8731e-03,  5.7410e-02,  2.3468e-02, -1.2294e-03,  3.3805e-02]],\n",
       "              \n",
       "                       [[ 2.1464e-02,  4.5124e-02, -4.4583e-02, -6.4193e-02,  2.8333e-02],\n",
       "                        [-4.1375e-02,  2.3532e-02, -3.6862e-02, -4.9610e-03,  7.6071e-03],\n",
       "                        [-2.1181e-02, -5.6144e-02,  5.3837e-02,  3.4964e-02,  5.5453e-02],\n",
       "                        [-6.3397e-02, -1.4255e-02,  5.3162e-02, -3.6599e-02, -2.6150e-02],\n",
       "                        [ 1.8385e-02, -2.2363e-02,  4.1486e-02,  3.7263e-02, -6.6371e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.8212e-02,  3.6275e-02, -3.3579e-02,  3.1037e-03,  1.4266e-02],\n",
       "                        [-6.4515e-02, -5.4930e-02,  7.6741e-03,  1.7196e-02, -2.7954e-02],\n",
       "                        [-4.0456e-02, -7.2169e-02, -3.7750e-02,  6.4324e-02, -2.9645e-02],\n",
       "                        [-4.5119e-02, -4.2879e-02,  5.9340e-02,  4.9274e-02, -4.4875e-02],\n",
       "                        [ 2.6909e-02,  5.8090e-03, -2.1123e-02,  6.7029e-02, -2.6550e-02]],\n",
       "              \n",
       "                       [[-1.2163e-02,  2.6469e-02,  3.1889e-03, -3.3576e-02, -3.4902e-02],\n",
       "                        [ 9.3993e-02, -2.5017e-02, -8.4990e-02, -1.0955e-01, -8.3853e-02],\n",
       "                        [ 9.5776e-03, -1.1481e-01, -9.9273e-02, -2.5047e-02, -4.1589e-02],\n",
       "                        [-4.4572e-02, -7.4695e-02, -4.5334e-02, -9.2387e-02, -7.2993e-02],\n",
       "                        [ 7.3873e-02,  5.7252e-02,  4.3048e-02,  3.1310e-03, -2.0948e-02]],\n",
       "              \n",
       "                       [[ 2.2407e-02, -4.0366e-02, -5.6492e-02, -3.8818e-02, -5.4944e-02],\n",
       "                        [-3.1224e-02,  1.5628e-02, -5.8158e-02, -3.7420e-02, -1.5219e-02],\n",
       "                        [-1.7202e-02, -9.9287e-02, -5.5844e-02, -7.9702e-02, -7.5049e-02],\n",
       "                        [ 1.0739e-02, -5.8963e-02, -1.1534e-01, -6.2207e-02, -2.2458e-02],\n",
       "                        [ 4.6471e-02, -8.8033e-02, -6.9407e-02, -6.1720e-02, -2.8730e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0986e-01, -1.4312e-02,  1.7148e-02,  1.9586e-02, -2.7036e-02],\n",
       "                        [ 9.9108e-02,  7.6110e-02,  7.7750e-03,  4.5093e-03,  2.8004e-02],\n",
       "                        [ 1.1955e-01,  1.6299e-01,  4.6342e-02, -2.3045e-02, -1.0982e-02],\n",
       "                        [ 4.7352e-02,  2.2843e-02,  4.4810e-02, -2.9501e-02,  5.0814e-02],\n",
       "                        [-1.0021e-01,  3.1827e-02, -7.2079e-02,  2.7170e-02,  1.0294e-01]],\n",
       "              \n",
       "                       [[ 9.9634e-03,  4.3608e-02,  5.6892e-02, -3.7933e-02,  8.2182e-03],\n",
       "                        [ 1.5137e-02, -5.3869e-02, -3.2795e-02,  1.2842e-02,  2.6410e-02],\n",
       "                        [-1.5545e-02, -3.2853e-02,  3.8948e-02,  1.4424e-02, -5.4130e-02],\n",
       "                        [-2.1001e-02,  4.5793e-02, -8.9011e-03,  2.9332e-02, -3.6294e-02],\n",
       "                        [ 7.5948e-02,  3.3195e-02,  1.0091e-01, -3.1698e-03, -2.3830e-03]],\n",
       "              \n",
       "                       [[-2.3784e-03, -3.5000e-02,  3.9515e-02, -6.5895e-03,  5.7804e-02],\n",
       "                        [-3.0158e-02, -4.2702e-02,  6.5712e-02,  2.8298e-02, -3.5418e-02],\n",
       "                        [-3.0673e-02, -3.6534e-02,  3.1125e-02, -2.0957e-03,  1.5533e-02],\n",
       "                        [-3.4853e-02,  9.6037e-03,  4.7628e-02, -5.1814e-02, -4.8282e-02],\n",
       "                        [ 3.5317e-02, -2.8839e-02, -6.4067e-03,  1.4788e-02, -4.5597e-02]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([ 0.0588, -0.0051, -0.0628, -0.0008, -0.0675, -0.0292,  0.0034, -0.0072,\n",
       "                       0.0302, -0.0206,  0.0119,  0.0666, -0.0516, -0.0739, -0.0263, -0.0096,\n",
       "                      -0.0297, -0.0658,  0.0102, -0.0285])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0111, -0.0146, -0.0978,  ...,  0.0552, -0.0303, -0.0356],\n",
       "                      [-0.1243,  0.0378, -0.0426,  ...,  0.0363,  0.0215,  0.0463],\n",
       "                      [-0.0079,  0.0263, -0.0169,  ..., -0.0543,  0.0118,  0.0773],\n",
       "                      ...,\n",
       "                      [ 0.0900, -0.0275,  0.0075,  ...,  0.0221,  0.0176,  0.0255],\n",
       "                      [-0.0709,  0.0132, -0.0098,  ..., -0.0329,  0.0154, -0.0099],\n",
       "                      [-0.0567, -0.0803,  0.0552,  ...,  0.0445,  0.0090, -0.0017]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.0344,  0.0646, -0.0239,  0.0702, -0.0039, -0.0051,  0.0140,  0.0539,\n",
       "                       0.0483,  0.0409, -0.0113,  0.0263,  0.0459,  0.0302,  0.0803,  0.0313,\n",
       "                      -0.0348,  0.0057,  0.0242,  0.0233, -0.0363,  0.0231,  0.0137, -0.0186,\n",
       "                       0.0248,  0.0123, -0.0099, -0.0054, -0.0584,  0.0203, -0.0275,  0.0028,\n",
       "                       0.0317,  0.0513,  0.0424, -0.0035,  0.0679,  0.0502,  0.0096, -0.0191,\n",
       "                      -0.0098,  0.0045,  0.0312,  0.0643, -0.0370, -0.0059,  0.0827,  0.0535,\n",
       "                       0.0067,  0.1013])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.1278, -0.1966, -0.0920, -0.0591, -0.1780, -0.1819, -0.1248, -0.2044,\n",
       "                       -0.0099, -0.2399,  0.2052, -0.1926, -0.1334,  0.2282, -0.1646, -0.1146,\n",
       "                        0.1446, -0.0989,  0.2324, -0.0738,  0.1406, -0.1206,  0.2104, -0.1402,\n",
       "                       -0.0838,  0.2878,  0.2416, -0.2390, -0.2104,  0.2186, -0.1914,  0.2145,\n",
       "                        0.2019, -0.0546, -0.0197, -0.1981,  0.1728, -0.1214, -0.1452,  0.2592,\n",
       "                       -0.2337, -0.0094,  0.1732, -0.0590,  0.0212,  0.3344, -0.1730, -0.0997,\n",
       "                       -0.0019, -0.1806],\n",
       "                      [ 0.0424,  0.1680,  0.0740,  0.2711,  0.2760, -0.1841,  0.1826,  0.2194,\n",
       "                       -0.2038,  0.1508, -0.0101,  0.1172,  0.2623,  0.1675,  0.3749,  0.1259,\n",
       "                       -0.1229,  0.1914, -0.1241, -0.0032, -0.1646,  0.1786, -0.2938, -0.1700,\n",
       "                       -0.0533, -0.1622, -0.0578, -0.2184, -0.0732,  0.1305, -0.1979, -0.1853,\n",
       "                       -0.2526,  0.0931,  0.2261, -0.2308, -0.1436,  0.3032, -0.2188, -0.2122,\n",
       "                        0.1418, -0.1216, -0.1868, -0.2818, -0.0214, -0.0643,  0.2311, -0.2557,\n",
       "                       -0.0160,  0.2828],\n",
       "                      [ 0.1997, -0.2637,  0.2156, -0.2393,  0.0897,  0.0252,  0.2313, -0.0418,\n",
       "                       -0.1479,  0.0043, -0.0940,  0.1757,  0.2141, -0.1275, -0.1906, -0.0370,\n",
       "                        0.1342,  0.0838,  0.2677, -0.1435, -0.1871, -0.0321,  0.1333,  0.2614,\n",
       "                        0.1133, -0.1169, -0.1470, -0.1161,  0.1551,  0.2029, -0.2372,  0.1484,\n",
       "                       -0.1055, -0.2065, -0.1229, -0.2207,  0.0198, -0.0983,  0.0508, -0.2174,\n",
       "                        0.1561,  0.0622,  0.1911, -0.1666,  0.2667,  0.0762,  0.2311, -0.1554,\n",
       "                       -0.2247, -0.0809],\n",
       "                      [ 0.1767, -0.1879, -0.0599,  0.2421, -0.1453,  0.2338,  0.2204,  0.2055,\n",
       "                       -0.0417,  0.2065, -0.0168,  0.0554, -0.1084, -0.2280, -0.2022, -0.1863,\n",
       "                        0.1160, -0.0790,  0.0727, -0.1313, -0.0499, -0.2623, -0.0599, -0.0242,\n",
       "                        0.2700, -0.0764, -0.1484,  0.2026,  0.2049,  0.1679,  0.2021, -0.1491,\n",
       "                        0.1335,  0.2482, -0.2018, -0.0532,  0.2619, -0.0989,  0.0252,  0.0199,\n",
       "                        0.1408,  0.2662,  0.0532, -0.1775,  0.0831, -0.2083,  0.0778, -0.1412,\n",
       "                       -0.0892, -0.1172],\n",
       "                      [ 0.1624,  0.1591, -0.1529, -0.0422,  0.2699,  0.2873,  0.2363, -0.0068,\n",
       "                       -0.2105, -0.0501, -0.1413, -0.1512,  0.0105, -0.1067, -0.0829,  0.3212,\n",
       "                       -0.3118,  0.2223, -0.0773,  0.0063,  0.2524,  0.2117,  0.0421,  0.2288,\n",
       "                        0.1448, -0.1689,  0.2124,  0.1525, -0.1847, -0.1428, -0.0696,  0.0662,\n",
       "                       -0.3074, -0.2178,  0.2240,  0.1859, -0.2947, -0.0130, -0.1874, -0.0550,\n",
       "                       -0.1785, -0.1794,  0.0262,  0.2266, -0.0805, -0.0353, -0.1685,  0.1375,\n",
       "                        0.1889, -0.0562],\n",
       "                      [ 0.0940,  0.1714,  0.0801,  0.2423, -0.0343, -0.0360, -0.2194, -0.1390,\n",
       "                        0.2426, -0.1879,  0.1771, -0.1154, -0.1528,  0.0287, -0.0130, -0.1107,\n",
       "                       -0.1734, -0.2500, -0.2055,  0.1979,  0.1657, -0.0861,  0.0454, -0.0992,\n",
       "                        0.0116,  0.2393, -0.1082,  0.1864,  0.1351, -0.1971,  0.2232, -0.1904,\n",
       "                        0.1797,  0.2542, -0.1703,  0.1549,  0.2322,  0.1231, -0.0456,  0.2215,\n",
       "                        0.1592, -0.0641, -0.1619,  0.1462, -0.0908, -0.1527, -0.1276,  0.1155,\n",
       "                        0.1991, -0.0031],\n",
       "                      [ 0.1191,  0.1323,  0.1746, -0.1404, -0.0668, -0.1396, -0.2858, -0.2670,\n",
       "                        0.0625, -0.1802, -0.1495,  0.0565,  0.2030,  0.1563, -0.2420,  0.0307,\n",
       "                       -0.2956, -0.2941, -0.1032, -0.0953, -0.2552,  0.2193,  0.2008,  0.2325,\n",
       "                       -0.2662,  0.2714,  0.2374, -0.0954, -0.2599, -0.0698, -0.1584,  0.1684,\n",
       "                        0.1894,  0.2234, -0.2320, -0.1838, -0.0466, -0.2004, -0.1660,  0.2811,\n",
       "                        0.1232, -0.2222, -0.3101,  0.2360, -0.1544,  0.0022, -0.2183,  0.1565,\n",
       "                        0.1871,  0.3148],\n",
       "                      [-0.0666, -0.2357, -0.1649,  0.0647, -0.1678,  0.2718,  0.0985,  0.1766,\n",
       "                       -0.1295,  0.2282,  0.2079,  0.0999, -0.0689,  0.0297, -0.1017, -0.0490,\n",
       "                        0.1390,  0.2229, -0.0103,  0.1237,  0.0551, -0.1960, -0.2617, -0.0617,\n",
       "                        0.2702, -0.0995,  0.0412, -0.1905,  0.1650, -0.0678, -0.2345, -0.1022,\n",
       "                       -0.0869, -0.1411,  0.2048,  0.1947, -0.2035,  0.2898,  0.2801,  0.0360,\n",
       "                       -0.0890,  0.0162,  0.1941, -0.1801,  0.2562,  0.1090,  0.2243,  0.1497,\n",
       "                       -0.1282, -0.2179],\n",
       "                      [-0.1212,  0.1540,  0.1607, -0.0005, -0.0917, -0.0214,  0.2048, -0.1248,\n",
       "                        0.2601, -0.1655, -0.2154,  0.1481, -0.1019,  0.1961, -0.0402, -0.0335,\n",
       "                        0.1493,  0.2019, -0.0483, -0.1575, -0.1215,  0.1935,  0.2093, -0.0275,\n",
       "                       -0.1420, -0.0477, -0.1493,  0.1860, -0.1046, -0.0825,  0.1882, -0.1409,\n",
       "                        0.1894, -0.0747, -0.1821,  0.1670,  0.0166, -0.1787, -0.0180, -0.0148,\n",
       "                        0.1536,  0.2515,  0.1371,  0.0368, -0.0620, -0.0699, -0.0618, -0.1059,\n",
       "                       -0.1293, -0.1016],\n",
       "                      [-0.2567,  0.1268, -0.2914,  0.0598,  0.2616,  0.2795,  0.1882, -0.1183,\n",
       "                        0.0038, -0.1688,  0.2056, -0.3014, -0.2084, -0.2449, -0.0715, -0.1883,\n",
       "                        0.0769,  0.1980, -0.1438,  0.1231,  0.2223, -0.0867,  0.1416, -0.2083,\n",
       "                        0.2459, -0.1149, -0.1271,  0.1719,  0.0681, -0.1521,  0.1857,  0.0803,\n",
       "                        0.1103, -0.0506,  0.1587,  0.1835, -0.0284, -0.0045,  0.2655, -0.0932,\n",
       "                       -0.2211,  0.2488,  0.1632,  0.2300, -0.0708,  0.0378, -0.1446, -0.1973,\n",
       "                        0.1849, -0.1241]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.1775,  0.1640,  0.1054, -0.0173, -0.1564, -0.0394, -0.0977, -0.1174,\n",
       "                       0.3474, -0.1394]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('../model/cnn/mnist_cnn.pt', map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
