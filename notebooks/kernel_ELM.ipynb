{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import loguru\n",
    "import time\n",
    "import json\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/elm_configs.json', 'r') as f:\n",
    "    configs = json.load(f)\n",
    "num_classes = configs['num_classes']\n",
    "num_hidden_layers = configs['num_hidden_layers']\n",
    "input_length = configs['input_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(-1, input_length).astype(np.float32) / 255.0\n",
    "x_test = x_test.reshape(-1, input_length).astype(np.float32) / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes).astype(np.float32)\n",
    "y_test = to_categorical(y_test, num_classes).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mean_squared_error(y, pred):\n",
    "    return 0.5 * np.mean((y - pred) ** 2)\n",
    "\n",
    "def _mean_abs_error(y, pred):\n",
    "    return np.mean(np.abs(y, pred))\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "\n",
    "def _fourier(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "\n",
    "def _hardlimit(x):\n",
    "    return (x >= 0).astype(int)\n",
    "\n",
    "\n",
    "def _identity(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "def getActivation(name):\n",
    "    if name not in ['sigmoid', 'fourier', 'hardlimit', 'identity']:\n",
    "        raise ValueError('Unknown activation function: %s' % name)\n",
    "    \n",
    "    return {\n",
    "        'sigmoid': _sigmoid,\n",
    "        'fourier': _fourier,\n",
    "        'hardlimit': _hardlimit,\n",
    "        'identity': _identity\n",
    "    }[name]\n",
    "\n",
    "\n",
    "def getLoss(name):\n",
    "    if name not in ['mse', 'mae']:\n",
    "        raise ValueError('Unknown loss function: %s' % name)\n",
    "    \n",
    "    return {\n",
    "        'mse': _mean_squared_error,\n",
    "        'mae': _mean_abs_error\n",
    "    }[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReELM:\n",
    "    def __init__(self, \n",
    "                 num_input_nodes: int, \n",
    "                 num_hidden_units: int, \n",
    "                 num_out_units: int,\n",
    "                 C: int=1,\n",
    "                 activation: str='sigmoid', \n",
    "                 loss: str ='mse', \n",
    "                 beta_init: np.ndarray=None, \n",
    "                 w_init: np.ndarray=None,\n",
    "                 use_bias: bool=True, \n",
    "                 bias_init: np.ndarray=None):\n",
    "        \n",
    "        self._num_input_nodes = num_input_nodes\n",
    "        self._num_hidden_units = num_hidden_units\n",
    "        self._num_out_units = num_out_units\n",
    "        self.C = C\n",
    "        self.I = np.eye(num_hidden_units, num_hidden_units)\n",
    "\n",
    "        self._activation = getActivation(activation)\n",
    "        self._loss = getLoss(loss)\n",
    "\n",
    "        if isinstance(beta_init, np.ndarray):\n",
    "            self._beta = beta_init\n",
    "        else:\n",
    "            self._beta = np.random.uniform(-1., 1., size=(self._num_hidden_units, self._num_out_units))\n",
    "\n",
    "        if isinstance(w_init, np.ndarray):\n",
    "            self._w = w_init\n",
    "        else:\n",
    "            self._w = np.random.uniform(-1, 1, size=(self._num_input_nodes, self._num_hidden_units))\n",
    "\n",
    "        if isinstance(bias_init, np.ndarray):\n",
    "            self._bias = bias_init\n",
    "        else:\n",
    "            if use_bias:\n",
    "                self._bias = np.random.uniform(-1, 1, size=(self._num_hidden_units,))\n",
    "            else:\n",
    "                self._bias = np.zeros(shape=(self._num_hidden_units,))\n",
    "\n",
    "        loguru.logger.debug(f'Beta: {self._beta.shape}')\n",
    "        loguru.logger.debug(f'Weights: {self._w.shape}')\n",
    "        loguru.logger.debug(f'Bias: {self._bias.shape}')\n",
    "    \n",
    "    def fit(self, X, y, display_time=False):\n",
    "        H = self._activation(X.dot(self._w) + self._bias)\n",
    "        \n",
    "        if display_time:\n",
    "            start_time = time.time()\n",
    "            \n",
    "        # Moore-Penrose pseudo inverse\n",
    "        H_pinv = np.linalg.pinv(H.T @ H + self.I / self.C)\n",
    "        \n",
    "        if display_time:\n",
    "            stop_time = time.time()\n",
    "            loguru.logger.debug(f'Pseudo inverse took {stop_time - start_time:.4f} seconds')\n",
    "        \n",
    "        self._beta = H_pinv @ H.T @ y\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        H = self._activation(X.dot(self._w) + self._bias)\n",
    "        return H.dot(self._beta)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        pred = self(X)\n",
    "        loss = self._loss(y, pred)\n",
    "        acc = np.sum(np.argmax(pred, axis=1) == np.argmax(y, axis=1)) / len(y)\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-05 16:07:18.676\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m41\u001b[0m - \u001b[34m\u001b[1mBeta: (2048, 10)\u001b[0m\n",
      "\u001b[32m2024-04-05 16:07:18.677\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1mWeights: (784, 2048)\u001b[0m\n",
      "\u001b[32m2024-04-05 16:07:18.678\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m43\u001b[0m - \u001b[34m\u001b[1mBias: (2048,)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# create instance of our model\n",
    "model = ReELM(\n",
    "    input_length,\n",
    "    num_hidden_layers,\n",
    "    num_classes,\n",
    "    use_bias=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-05 16:07:29.271\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m56\u001b[0m - \u001b[34m\u001b[1mPseudo inverse took 4.7705 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(x_train, y_train, display_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.008866\n",
      "train acc: 0.960133\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "print('train loss: %f' % train_loss)\n",
    "print('train acc: %f' % train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.009346\n",
      "val acc: 0.952700\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print('val loss: %f' % val_loss)\n",
    "print('val acc: %f' % val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelELM:\n",
    "    def __init__(self, \n",
    "                 num_input_nodes: int, \n",
    "                 num_hidden_units: int, \n",
    "                 num_out_units: int,\n",
    "                 C: int=1,\n",
    "                 activation: str='sigmoid', \n",
    "                 loss: str ='mse', \n",
    "                 beta_init: np.ndarray=None, \n",
    "                 w_init: np.ndarray=None,\n",
    "                 use_bias: bool=True, \n",
    "                 bias_init: np.ndarray=None):\n",
    "        \n",
    "        self._num_input_nodes = num_input_nodes\n",
    "        self._num_hidden_units = num_hidden_units\n",
    "        self._num_out_units = num_out_units\n",
    "        self.C = C\n",
    "        self.I = np.eye(num_hidden_units, num_hidden_units)\n",
    "\n",
    "        self._activation = getActivation(activation)\n",
    "        self._loss = getLoss(loss)\n",
    "\n",
    "        if isinstance(beta_init, np.ndarray):\n",
    "            self._beta = beta_init\n",
    "        else:\n",
    "            self._beta = np.random.uniform(-1., 1., size=(self._num_hidden_units, self._num_out_units))\n",
    "\n",
    "        if isinstance(w_init, np.ndarray):\n",
    "            self._w = w_init\n",
    "        else:\n",
    "            self._w = np.random.uniform(-1, 1, size=(self._num_input_nodes, self._num_hidden_units))\n",
    "\n",
    "        if isinstance(bias_init, np.ndarray):\n",
    "            self._bias = bias_init\n",
    "        else:\n",
    "            if use_bias:\n",
    "                self._bias = np.random.uniform(-1, 1, size=(self._num_hidden_units,))\n",
    "            else:\n",
    "                self._bias = np.zeros(shape=(self._num_hidden_units,))\n",
    "\n",
    "        loguru.logger.debug(f'Beta: {self._beta.shape}')\n",
    "        loguru.logger.debug(f'Weights: {self._w.shape}')\n",
    "        loguru.logger.debug(f'Bias: {self._bias.shape}')\n",
    "    \n",
    "    def fit(self, X, y, display_time=False):\n",
    "        H = self._activation(X.dot(self._w) + self._bias)\n",
    "        \n",
    "        if display_time:\n",
    "            start_time = time.time()\n",
    "            \n",
    "        # Moore-Penrose pseudo inverse\n",
    "        H_pinv = np.linalg.pinv(H.T @ H + self.I / self.C)\n",
    "        \n",
    "        if display_time:\n",
    "            stop_time = time.time()\n",
    "            loguru.logger.debug(f'Pseudo inverse took {stop_time - start_time:.4f} seconds')\n",
    "        \n",
    "        self._beta = H_pinv @ H.T @ y\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        H = self._activation(X.dot(self._w) + self._bias)\n",
    "        return H.dot(self._beta)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        pred = self(X)\n",
    "        loss = self._loss(y, pred)\n",
    "        acc = np.sum(np.argmax(pred, axis=1) == np.argmax(y, axis=1)) / len(y)\n",
    "        return loss, acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
